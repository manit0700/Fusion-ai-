{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetrievalQA\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SQLDatabase\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tool\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_react_agent, AgentExecutor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import requests\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS \n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.agents import Tool\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining embedding model and directory to save the embeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "persistant_directory = os.getcwd() + '\\\\db\\\\'\n",
    "documents = []\n",
    "file_name = os.getcwd() + \"/dataset/odyssey.txt\"\n",
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# Reading the txt file \n",
    "def load_txt_file(file_path):  \n",
    "    loader = TextLoader(file_path, encoding = 'UTF-8')\n",
    "    book_docs = loader.load()\n",
    "    return book_docs\n",
    "\n",
    "# Splitting the txt file into chunks of 1000 character with 200 character_overlap\n",
    "def split_doc_into_chunks(file_path):\n",
    "    documents = load_txt_file(file_path)\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs\n",
    "\n",
    "def save_vector_store(docs, folder_path):\n",
    "    # use when you are using OpenAI model\n",
    "    # embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "    # using ChatGroq Llama model\n",
    "    \n",
    "    vector_store = FAISS.from_documents(docs, embedding_model)\n",
    "    \n",
    "    # Save the FAISS index to the specified folder\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    vector_store.save_local(folder_path)\n",
    "    print(f\"Vector store saved to {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_20556\\4117310523.py:10: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "Created a chunk of size 1141, which is longer than the specified 1000\n",
      "Created a chunk of size 2086, which is longer than the specified 1000\n",
      "Created a chunk of size 1121, which is longer than the specified 1000\n",
      "Created a chunk of size 1366, which is longer than the specified 1000\n",
      "Created a chunk of size 1011, which is longer than the specified 1000\n",
      "Created a chunk of size 1639, which is longer than the specified 1000\n",
      "Created a chunk of size 1219, which is longer than the specified 1000\n",
      "Created a chunk of size 1875, which is longer than the specified 1000\n",
      "Created a chunk of size 1307, which is longer than the specified 1000\n",
      "Created a chunk of size 2271, which is longer than the specified 1000\n",
      "Created a chunk of size 1430, which is longer than the specified 1000\n",
      "Created a chunk of size 1763, which is longer than the specified 1000\n",
      "Created a chunk of size 1575, which is longer than the specified 1000\n",
      "Created a chunk of size 1028, which is longer than the specified 1000\n",
      "Created a chunk of size 1149, which is longer than the specified 1000\n",
      "Created a chunk of size 1199, which is longer than the specified 1000\n",
      "Created a chunk of size 1604, which is longer than the specified 1000\n",
      "Created a chunk of size 1832, which is longer than the specified 1000\n",
      "Created a chunk of size 1093, which is longer than the specified 1000\n",
      "Created a chunk of size 1995, which is longer than the specified 1000\n",
      "Created a chunk of size 1463, which is longer than the specified 1000\n",
      "Created a chunk of size 1098, which is longer than the specified 1000\n",
      "Created a chunk of size 1053, which is longer than the specified 1000\n",
      "Created a chunk of size 1027, which is longer than the specified 1000\n",
      "Created a chunk of size 1315, which is longer than the specified 1000\n",
      "Created a chunk of size 1627, which is longer than the specified 1000\n",
      "Created a chunk of size 1063, which is longer than the specified 1000\n",
      "Created a chunk of size 1051, which is longer than the specified 1000\n",
      "Created a chunk of size 1265, which is longer than the specified 1000\n",
      "Created a chunk of size 1202, which is longer than the specified 1000\n",
      "Created a chunk of size 1509, which is longer than the specified 1000\n",
      "Created a chunk of size 1153, which is longer than the specified 1000\n",
      "Created a chunk of size 1043, which is longer than the specified 1000\n",
      "Created a chunk of size 1336, which is longer than the specified 1000\n",
      "Created a chunk of size 1111, which is longer than the specified 1000\n",
      "Created a chunk of size 1205, which is longer than the specified 1000\n",
      "Created a chunk of size 1158, which is longer than the specified 1000\n",
      "Created a chunk of size 1004, which is longer than the specified 1000\n",
      "Created a chunk of size 1155, which is longer than the specified 1000\n",
      "Created a chunk of size 1085, which is longer than the specified 1000\n",
      "Created a chunk of size 1064, which is longer than the specified 1000\n",
      "Created a chunk of size 1078, which is longer than the specified 1000\n",
      "Created a chunk of size 1827, which is longer than the specified 1000\n",
      "Created a chunk of size 1188, which is longer than the specified 1000\n",
      "Created a chunk of size 1058, which is longer than the specified 1000\n",
      "Created a chunk of size 1226, which is longer than the specified 1000\n",
      "Created a chunk of size 1419, which is longer than the specified 1000\n",
      "Created a chunk of size 1223, which is longer than the specified 1000\n",
      "Created a chunk of size 1284, which is longer than the specified 1000\n",
      "Created a chunk of size 1112, which is longer than the specified 1000\n",
      "Created a chunk of size 1437, which is longer than the specified 1000\n",
      "Created a chunk of size 1030, which is longer than the specified 1000\n",
      "Created a chunk of size 1094, which is longer than the specified 1000\n",
      "Created a chunk of size 1079, which is longer than the specified 1000\n",
      "Created a chunk of size 1073, which is longer than the specified 1000\n",
      "Created a chunk of size 1550, which is longer than the specified 1000\n",
      "Created a chunk of size 1737, which is longer than the specified 1000\n",
      "Created a chunk of size 1038, which is longer than the specified 1000\n",
      "Created a chunk of size 1011, which is longer than the specified 1000\n",
      "Created a chunk of size 1382, which is longer than the specified 1000\n",
      "Created a chunk of size 1184, which is longer than the specified 1000\n",
      "Created a chunk of size 1378, which is longer than the specified 1000\n",
      "Created a chunk of size 1052, which is longer than the specified 1000\n",
      "Created a chunk of size 1402, which is longer than the specified 1000\n",
      "Created a chunk of size 1047, which is longer than the specified 1000\n",
      "Created a chunk of size 1163, which is longer than the specified 1000\n",
      "Created a chunk of size 1403, which is longer than the specified 1000\n",
      "Created a chunk of size 1077, which is longer than the specified 1000\n",
      "Created a chunk of size 1588, which is longer than the specified 1000\n",
      "Created a chunk of size 1228, which is longer than the specified 1000\n",
      "Created a chunk of size 1337, which is longer than the specified 1000\n",
      "Created a chunk of size 1469, which is longer than the specified 1000\n",
      "Created a chunk of size 1269, which is longer than the specified 1000\n",
      "Created a chunk of size 1106, which is longer than the specified 1000\n",
      "Created a chunk of size 1492, which is longer than the specified 1000\n",
      "Created a chunk of size 1219, which is longer than the specified 1000\n",
      "Created a chunk of size 1165, which is longer than the specified 1000\n",
      "Created a chunk of size 1115, which is longer than the specified 1000\n",
      "Created a chunk of size 1505, which is longer than the specified 1000\n",
      "Created a chunk of size 1549, which is longer than the specified 1000\n",
      "Created a chunk of size 1309, which is longer than the specified 1000\n",
      "Created a chunk of size 1290, which is longer than the specified 1000\n",
      "Created a chunk of size 1593, which is longer than the specified 1000\n",
      "Created a chunk of size 1292, which is longer than the specified 1000\n",
      "Created a chunk of size 1136, which is longer than the specified 1000\n",
      "Created a chunk of size 1162, which is longer than the specified 1000\n",
      "Created a chunk of size 1003, which is longer than the specified 1000\n",
      "Created a chunk of size 1065, which is longer than the specified 1000\n",
      "Created a chunk of size 1403, which is longer than the specified 1000\n",
      "Created a chunk of size 1564, which is longer than the specified 1000\n",
      "Created a chunk of size 1776, which is longer than the specified 1000\n",
      "Created a chunk of size 1006, which is longer than the specified 1000\n",
      "Created a chunk of size 1377, which is longer than the specified 1000\n",
      "Created a chunk of size 1289, which is longer than the specified 1000\n",
      "Created a chunk of size 1727, which is longer than the specified 1000\n",
      "Created a chunk of size 1555, which is longer than the specified 1000\n",
      "Created a chunk of size 1619, which is longer than the specified 1000\n",
      "Created a chunk of size 1059, which is longer than the specified 1000\n",
      "Created a chunk of size 1013, which is longer than the specified 1000\n",
      "Created a chunk of size 1180, which is longer than the specified 1000\n",
      "Created a chunk of size 1897, which is longer than the specified 1000\n",
      "Created a chunk of size 1412, which is longer than the specified 1000\n",
      "Created a chunk of size 1740, which is longer than the specified 1000\n",
      "Created a chunk of size 1126, which is longer than the specified 1000\n",
      "Created a chunk of size 1003, which is longer than the specified 1000\n",
      "Created a chunk of size 1126, which is longer than the specified 1000\n",
      "Created a chunk of size 1384, which is longer than the specified 1000\n",
      "Created a chunk of size 1688, which is longer than the specified 1000\n",
      "Created a chunk of size 1035, which is longer than the specified 1000\n",
      "Created a chunk of size 2424, which is longer than the specified 1000\n",
      "Created a chunk of size 2028, which is longer than the specified 1000\n",
      "Created a chunk of size 1697, which is longer than the specified 1000\n",
      "Created a chunk of size 2474, which is longer than the specified 1000\n",
      "Created a chunk of size 1327, which is longer than the specified 1000\n",
      "Created a chunk of size 1225, which is longer than the specified 1000\n",
      "Created a chunk of size 1118, which is longer than the specified 1000\n",
      "Created a chunk of size 1999, which is longer than the specified 1000\n",
      "Created a chunk of size 2401, which is longer than the specified 1000\n",
      "Created a chunk of size 1227, which is longer than the specified 1000\n",
      "Created a chunk of size 1074, which is longer than the specified 1000\n",
      "Created a chunk of size 1810, which is longer than the specified 1000\n",
      "Created a chunk of size 1065, which is longer than the specified 1000\n",
      "Created a chunk of size 1528, which is longer than the specified 1000\n",
      "Created a chunk of size 1122, which is longer than the specified 1000\n",
      "Created a chunk of size 2149, which is longer than the specified 1000\n",
      "Created a chunk of size 1226, which is longer than the specified 1000\n",
      "Created a chunk of size 1008, which is longer than the specified 1000\n",
      "Created a chunk of size 1504, which is longer than the specified 1000\n",
      "Created a chunk of size 1119, which is longer than the specified 1000\n",
      "Created a chunk of size 1107, which is longer than the specified 1000\n",
      "Created a chunk of size 1194, which is longer than the specified 1000\n",
      "Created a chunk of size 1031, which is longer than the specified 1000\n",
      "Created a chunk of size 1034, which is longer than the specified 1000\n",
      "Created a chunk of size 1386, which is longer than the specified 1000\n",
      "Created a chunk of size 1235, which is longer than the specified 1000\n",
      "Created a chunk of size 1004, which is longer than the specified 1000\n",
      "Created a chunk of size 1792, which is longer than the specified 1000\n",
      "Created a chunk of size 1132, which is longer than the specified 1000\n",
      "Created a chunk of size 1055, which is longer than the specified 1000\n",
      "Created a chunk of size 1189, which is longer than the specified 1000\n",
      "Created a chunk of size 1528, which is longer than the specified 1000\n",
      "Created a chunk of size 2049, which is longer than the specified 1000\n",
      "Created a chunk of size 1097, which is longer than the specified 1000\n",
      "Created a chunk of size 1860, which is longer than the specified 1000\n",
      "Created a chunk of size 1296, which is longer than the specified 1000\n",
      "Created a chunk of size 1369, which is longer than the specified 1000\n",
      "Created a chunk of size 1121, which is longer than the specified 1000\n",
      "Created a chunk of size 1285, which is longer than the specified 1000\n",
      "Created a chunk of size 1736, which is longer than the specified 1000\n",
      "Created a chunk of size 1637, which is longer than the specified 1000\n",
      "Created a chunk of size 1184, which is longer than the specified 1000\n",
      "Created a chunk of size 1045, which is longer than the specified 1000\n",
      "Created a chunk of size 1132, which is longer than the specified 1000\n",
      "Created a chunk of size 1674, which is longer than the specified 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'FAISS vector store saved in c:\\\\Users\\\\ADMIN\\\\Tution\\\\Langchain_Leaern\\\\Project\\\\db\\\\. Skipping save.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_embeddings_to_db(folder_path, model_name):\n",
    "\n",
    "    faiss_index_path = os.getcwd() + \"\\db\\index.faiss\"\n",
    "    faiss_pkl_path = os.getcwd() + \"\\db\\index.pkl\"\n",
    "\n",
    "    if os.path.exists(faiss_index_path) and os.path.exists(faiss_pkl_path):\n",
    "        return f\"FAISS vector store already exists in {folder_path}. Skipping save.\"\n",
    "    else:\n",
    "        # Initialize Llama embeddings using Hugging Face\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "        \n",
    "        docs = split_doc_into_chunks(file_name)\n",
    "        # Generate embeddings and create FAISS vector store\n",
    "        vector_store = FAISS.from_documents(docs, embeddings)\n",
    "        \n",
    "        # Save the FAISS vector store locally in the db folder\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        vector_store.save_local(folder_path)\n",
    "        return f\"FAISS vector store saved in {folder_path}. Skipping save.\"\n",
    "    \n",
    "save_embeddings_to_db(persistant_directory, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I\\'m an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 38, 'total_tokens': 61, 'completion_time': 0.109223244, 'prompt_time': 0.012459811, 'queue_time': 0.052747063, 'total_time': 0.121683055}, 'model_name': 'Llama-3.3-70b-Versatile', 'system_fingerprint': 'fp_c0cfa69934', 'finish_reason': 'stop', 'logprobs': None}, id='run-7702067e-73c2-4de9-8f87-9d843ea4cfbc-0', usage_metadata={'input_tokens': 38, 'output_tokens': 23, 'total_tokens': 61})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# llm = OpenAI()\n",
    "\n",
    "llm = ChatGroq(model=\"Llama-3.3-70b-Versatile\")\n",
    "llm.invoke(\"who are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inilization of WeaperAPI class so when a request output come it format in proper json format \n",
    "\n",
    "def get_current_weather(city_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Get current weather for a city\n",
    "    units: metric (Celsius) or imperial (Fahrenheit)\n",
    "    \"\"\"\n",
    "    endpoint = f\"http://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\n",
    "        \"q\": city_name,\n",
    "        \"appid\": weather_api_key,\n",
    "        \"units\": \"metric\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(endpoint, params=params)\n",
    "        response.raise_for_status()  # Raise exception for bad status codes\n",
    "        data = response.json()\n",
    "        \n",
    "        return {\n",
    "            \"city\": data[\"name\"],\n",
    "            \"temperature\": data[\"main\"][\"temp\"],\n",
    "            \"feels_like\": data[\"main\"][\"feels_like\"],\n",
    "            \"humidity\": data[\"main\"][\"humidity\"],\n",
    "            \"description\": data[\"weather\"][0][\"description\"],\n",
    "            \"wind_speed\": data[\"wind\"][\"speed\"]\n",
    "        }\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error fetching weather data: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_k=3\n",
    "# query=\"who is auther mother\"\n",
    "\n",
    "# def retrieve_relevant_documents(query, folder_path, top_k, model_name):\n",
    "#     \"\"\"\n",
    "#     Retrieves relevant documents from the FAISS vector store.\n",
    "\n",
    "#     Args:\n",
    "#         folder_path (str): Path to the folder where the vector store is saved.\n",
    "#         query (str): The query to search for relevant documents.\n",
    "#         top_k (int): Number of top relevant documents to retrieve.\n",
    "#         model_name (str): The Hugging Face model used for embeddings.\n",
    "\n",
    "#     Returns:\n",
    "#         list: A list of the top-k relevant documents.\n",
    "#     \"\"\"\n",
    "#     # Initialize Llama embeddings using Hugging Face\n",
    "#     embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    \n",
    "#     # Load the FAISS vector store\n",
    "#     vector_store = FAISS.load_local(folder_path, embeddings, allow_dangerous_deserialization=True)\n",
    "#     print(f\"Vector store loaded from {folder_path}\")\n",
    "    \n",
    "#     # Perform similarity search\n",
    "#     results = vector_store.similarity_search(query, k=top_k)\n",
    "#     return results\n",
    "\n",
    "# retrieve_relevant_documents(query, persistant_directory, 2, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rag_retrieval_chain():\n",
    "    \"\"\"\n",
    "    Initializes the RAG Retrieval QA chain with the FAISS index from the 'db' folder.\n",
    "    \"\"\"\n",
    "    # Load the FAISS index\n",
    "    embedding = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "    db = FAISS.load_local(\"db\", embedding, allow_dangerous_deserialization=True)\n",
    "\n",
    "    # Define the retriever\n",
    "    retriever = db.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\"k\": 2, \"score_threshold\": 0.1}\n",
    "    )\n",
    "\n",
    "    # Define the prompt\n",
    "    prompt_template = \"\"\"Read the Question twice based on the provided context, respond to the question below while adhering to these guidelines:\n",
    "    1. If the answer is not found, do not speculate. Instead, state, \"I do not know the answer.\"\n",
    "    2. If the answer is found, provide a clear and concise response in no more than ten sentences.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "    # Create the Retrieval QA chain\n",
    "    retriever_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "\n",
    "    return retriever_chain\n",
    "\n",
    "weather_api_key = os.getenv(\"WEATHER_API_KEY\")\n",
    "\n",
    "def get_current_weather(city_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Get current weather for a city\n",
    "    units: metric (Celsius) or imperial (Fahrenheit)\n",
    "    \"\"\"\n",
    "    endpoint = f\"http://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\n",
    "        \"q\": city_name,\n",
    "        \"appid\": weather_api_key,\n",
    "        \"units\": \"metric\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(endpoint, params=params)\n",
    "        response.raise_for_status()  # Raise exception for bad status codes\n",
    "        data = response.json()\n",
    "        \n",
    "        return {\n",
    "            \"city\": data[\"name\"],\n",
    "            \"temperature\": data[\"main\"][\"temp\"],\n",
    "            \"feels_like\": data[\"main\"][\"feels_like\"],\n",
    "            \"humidity\": data[\"main\"][\"humidity\"],\n",
    "            \"description\": data[\"weather\"][0][\"description\"],\n",
    "            \"wind_speed\": data[\"wind\"][\"speed\"]\n",
    "        }\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error fetching weather data: {e}\"\n",
    "\n",
    "def get_schame(_):    \n",
    "    db_url = \"mysql+mysqlconnector://root:1234@localhost:3306/employee_management\"\n",
    "    db = SQLDatabase.from_uri(db_url)\n",
    "    return db.get_table_info()\n",
    "\n",
    "def run_query(query):\n",
    "    db_url = \"mysql+mysqlconnector://root:1234@localhost:3306/employee_management\"\n",
    "    db = SQLDatabase.from_uri(db_url)\n",
    "    return db.run(query)\n",
    "\n",
    "def get_table_information(table_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a natural language response to questions about database tables by:\n",
    "    1. Converting the question to SQL\n",
    "    2. Executing the SQL query\n",
    "    3. Converting the SQL results to natural language\n",
    "    \n",
    "    Args:\n",
    "        table_query (str): The user's question about the database\n",
    "        \n",
    "    Returns:\n",
    "        str: Natural language response based on the SQL query results\n",
    "    \"\"\"\n",
    "    \n",
    "    template = \"\"\"\n",
    "    Based on the table schema below, write a valid SQL query that answers the user's question:\n",
    "    NOTE: Ensure the query is syntactically correct and does not include markdown or extraneous text.\n",
    "    {schema}\n",
    "\n",
    "    Question: {question}\n",
    "    SQL Query:\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    sql_chain = (\n",
    "        RunnablePassthrough.assign(schema=get_schame)\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    template = \"\"\"\n",
    "    Based on the table schema, user's question, SQL query, and query results, write a concise and accurate natural language response:\n",
    "    {schema}\n",
    "\n",
    "    Question: {question}\n",
    "    SQL Query: {query}\n",
    "    SQL Response: {response}\n",
    "    Response:\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    full_chain = (\n",
    "        RunnablePassthrough.assign(query=sql_chain).assign(\n",
    "            schema=get_schame,\n",
    "            response= lambda x: run_query(x[\"query\"])\n",
    "        )\n",
    "        | prompt\n",
    "        | llm\n",
    "    )\n",
    "\n",
    "    return full_chain.invoke({\"question\": table_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1, datetime.datetime(2024, 4, 16, 20, 58, 6), datetime.datetime(2024, 5, 4, 21, 2, 59), '595-898-3808x963', '001-700-825-0718x38604', 2487, Decimal('44.99')), (2, 48, datetime.datetime(2024, 7, 4, 21, 45, 22), datetime.datetime(2024, 8, 19, 15, 7, 28), '(706)024-1538x3012', '769.200.5537', 1411, Decimal('17.64')), (3, 29, datetime.datetime(2024, 9, 30, 22, 28, 51), datetime.datetime(2024, 6, 20, 5, 58, 48), '996-813-4197x7204', '001-719-167-5836x240', 1565, Decimal('46.55')), (4, 50, datetime.datetime(2024, 8, 28, 18, 45), datetime.datetime(2024, 6, 4, 19, 9, 59), '+1-889-620-8735x1985', '710-760-3174x34148', 2620, Decimal('2.21')), (5, 37, datetime.datetime(2024, 7, 12, 17, 21, 12), datetime.datetime(2024, 1, 28, 6, 29, 54), '715-593-0574x0122', '206-484-7237x7914', 2377, Decimal('32.15')), (6, 20, datetime.datetime(2024, 4, 25, 1, 7, 8), datetime.datetime(2024, 2, 5, 21, 6, 44), '709-028-4766x774', '9389653135', 2151, Decimal('14.83')), (7, 7, datetime.datetime(2024, 6, 26, 11, 20, 30), datetime.datetime(2024, 8, 25, 21, 31, 8), '177-375-2796x3126', '(795)369-4209x743', 2572, Decimal('2.13')), (8, 24, datetime.datetime(2024, 3, 15, 6, 40, 44), datetime.datetime(2024, 4, 28, 3, 8, 11), '066.077.5349', '+1-871-119-8133', 938, Decimal('9.95')), (9, 15, datetime.datetime(2024, 8, 29, 14, 15, 44), datetime.datetime(2024, 7, 18, 17, 51, 29), '(780)480-7582x62141', '(900)678-0302', 1890, Decimal('38.30')), (10, 44, datetime.datetime(2024, 6, 16, 6, 51, 46), datetime.datetime(2024, 3, 5, 10, 22, 52), '830.865.0987x9801', '142.351.2442x77708', 559, Decimal('4.92')), (11, 35, datetime.datetime(2024, 7, 2, 3, 2, 45), datetime.datetime(2024, 8, 11, 17, 51, 6), '277-357-8157', '+1-817-360-6795x4282', 162, Decimal('25.23')), (12, 49, datetime.datetime(2024, 2, 20, 23, 53, 41), datetime.datetime(2024, 4, 7, 14, 46, 13), '711-542-4981x4802', '(550)893-1554x03723', 2744, Decimal('17.68')), (13, 11, datetime.datetime(2024, 3, 11, 5, 17, 3), datetime.datetime(2024, 4, 10, 13, 41), '155.939.6664', '8272110283', 378, Decimal('11.90')), (14, 40, datetime.datetime(2024, 1, 1, 16, 14, 53), datetime.datetime(2024, 5, 27, 18, 13, 25), '001-873-462-3548x88387', '136.927.1755', 2306, Decimal('46.26')), (15, 33, datetime.datetime(2024, 2, 11, 16, 37, 9), datetime.datetime(2024, 5, 13, 7, 57, 53), '017.843.1644', '001-300-795-1026x33834', 2086, Decimal('34.45')), (16, 17, datetime.datetime(2024, 7, 17, 6, 10, 28), datetime.datetime(2024, 6, 17, 12, 35, 54), '(617)813-6927', '995-935-3013', 2436, Decimal('46.70')), (17, 37, datetime.datetime(2024, 6, 30, 19, 45, 16), datetime.datetime(2024, 1, 10, 20, 53), '996.853.7611', '528.103.4058x14336', 607, Decimal('43.74')), (18, 47, datetime.datetime(2024, 1, 24, 6, 43, 55), datetime.datetime(2024, 4, 13, 16, 31, 1), '441.290.2318x2050', '(081)348-6168', 207, Decimal('6.97')), (19, 25, datetime.datetime(2024, 3, 12, 8, 40, 37), datetime.datetime(2024, 2, 25, 20, 29, 6), '+1-622-610-7178x21939', '197.081.0560', 104, Decimal('29.76')), (20, 16, datetime.datetime(2024, 2, 7, 11, 19, 23), datetime.datetime(2024, 10, 1, 21, 41, 37), '(285)418-8603', '451.795.2852x826', 2304, Decimal('3.86')), (21, 8, datetime.datetime(2024, 5, 24, 18, 34, 51), datetime.datetime(2024, 1, 7, 12, 9, 37), '+1-731-647-1038x439', '080-907-8154x29144', 462, Decimal('22.06')), (22, 38, datetime.datetime(2024, 7, 26, 17, 10, 12), datetime.datetime(2024, 8, 1, 15, 34, 28), '410.831.9647x3009', '975.850.3365', 378, Decimal('38.33')), (23, 23, datetime.datetime(2024, 5, 15, 2, 34, 23), datetime.datetime(2024, 1, 19, 17, 3, 59), '026.313.6340x82853', '430-238-7735x403', 341, Decimal('43.17')), (24, 31, datetime.datetime(2024, 5, 3, 0, 1, 30), datetime.datetime(2024, 3, 11, 2, 33, 10), '021-703-3843', '+1-835-704-6994x3789', 1548, Decimal('23.24')), (25, 18, datetime.datetime(2024, 6, 2, 8, 33, 16), datetime.datetime(2024, 8, 1, 18, 19, 56), '(396)635-3121', '(528)378-9638x2318', 1550, Decimal('3.99')), (26, 27, datetime.datetime(2024, 6, 21, 11, 31, 53), datetime.datetime(2024, 7, 23, 14, 24, 1), '485-984-4363x9109', '609.419.3179', 2420, Decimal('16.00')), (27, 27, datetime.datetime(2024, 5, 29, 6, 17, 5), datetime.datetime(2024, 10, 4, 23, 25, 58), '284-771-2059', '(321)308-4511', 316, Decimal('17.66')), (28, 23, datetime.datetime(2024, 1, 1, 23, 48, 3), datetime.datetime(2024, 2, 12, 14, 1, 29), '001-158-322-2685x450', '211.864.4300', 860, Decimal('5.14')), (29, 50, datetime.datetime(2024, 5, 14, 10, 44, 30), datetime.datetime(2024, 1, 10, 5, 59, 11), '6591354748', '+1-180-310-3987x13500', 1511, Decimal('28.23')), (30, 10, datetime.datetime(2024, 3, 26, 9, 43, 21), datetime.datetime(2024, 7, 11, 17, 11, 29), '+1-429-669-2958x6508', '001-952-615-4608x629', 1837, Decimal('34.99')), (31, 40, datetime.datetime(2024, 6, 21, 14, 20, 43), datetime.datetime(2024, 2, 9, 18, 16, 54), '(261)692-8641x8614', '(427)774-8162x11271', 1257, Decimal('27.61')), (32, 32, datetime.datetime(2024, 8, 16, 20, 6, 51), datetime.datetime(2024, 10, 1, 21, 37, 33), '(891)948-4201x97117', '001-475-022-4233x9608', 1470, Decimal('47.35')), (33, 42, datetime.datetime(2024, 3, 15, 2, 7, 59), datetime.datetime(2024, 6, 25, 4, 54, 27), '001-808-175-0614x3518', '001-974-717-7929', 896, Decimal('17.45')), (34, 34, datetime.datetime(2024, 6, 21, 11, 0, 20), datetime.datetime(2024, 7, 25, 1, 10, 43), '981-684-3173x73480', '001-202-349-3741x4002', 328, Decimal('40.44')), (35, 21, datetime.datetime(2024, 6, 2, 8, 45, 8), datetime.datetime(2024, 2, 18, 14, 48, 43), '001-171-416-5782', '(793)058-0030x70208', 1659, Decimal('46.19')), (36, 50, datetime.datetime(2024, 1, 30, 13, 45, 57), datetime.datetime(2024, 7, 30, 18, 58, 37), '001-637-417-5861x7577', '001-790-324-8569x766', 336, Decimal('41.81')), (37, 49, datetime.datetime(2024, 3, 26, 22, 32, 7), datetime.datetime(2024, 3, 28, 4, 12, 57), '(378)993-9081', '(268)529-5203', 2508, Decimal('25.64')), (38, 36, datetime.datetime(2024, 3, 17, 12, 33, 13), datetime.datetime(2024, 7, 2, 5, 0, 20), '001-668-425-0305x0947', '4803982479', 606, Decimal('9.69')), (39, 17, datetime.datetime(2024, 2, 27, 7, 49, 39), datetime.datetime(2024, 6, 12, 3, 14, 11), '(570)869-7111x438', '357.066.5173x289', 1332, Decimal('6.67')), (40, 23, datetime.datetime(2024, 5, 2, 0, 14, 22), datetime.datetime(2024, 4, 6, 4, 6, 35), '115.900.4614x572', '236-423-8229x02477', 2654, Decimal('26.37')), (41, 21, datetime.datetime(2024, 9, 29, 18, 11, 53), datetime.datetime(2024, 6, 23, 8, 7, 19), '871.049.5047', '106.878.9914x63957', 1134, Decimal('43.32')), (42, 37, datetime.datetime(2024, 1, 2, 22, 30, 28), datetime.datetime(2024, 6, 27, 0, 35, 28), '251-951-3064', '831.655.3558x64134', 1044, Decimal('45.82')), (43, 11, datetime.datetime(2024, 4, 7, 21, 28, 43), datetime.datetime(2024, 1, 8, 6, 11, 39), '+1-433-934-1236x383', '(886)082-4440x8408', 472, Decimal('43.15')), (44, 40, datetime.datetime(2024, 8, 6, 7, 18, 49), datetime.datetime(2024, 9, 24, 5, 12, 46), '001-942-855-8411', '187-897-7697', 2150, Decimal('29.63')), (45, 11, datetime.datetime(2024, 8, 1, 23, 9, 18), datetime.datetime(2024, 9, 11, 8, 39, 8), '+1-631-621-4262x8759', '+1-740-495-8498', 1187, Decimal('18.84')), (46, 30, datetime.datetime(2024, 8, 9, 16, 41, 37), datetime.datetime(2024, 1, 4, 16, 15, 54), '+1-271-996-4954', '091-009-0047', 1114, Decimal('24.38')), (47, 3, datetime.datetime(2024, 9, 4, 19, 13, 54), datetime.datetime(2024, 3, 23, 22, 21, 47), '444.280.5691', '5058985623', 401, Decimal('30.48')), (48, 16, datetime.datetime(2024, 4, 13, 15, 54, 17), datetime.datetime(2024, 1, 17, 13, 4, 4), '5515070618', '001-843-728-8833x29079', 1045, Decimal('22.95')), (49, 14, datetime.datetime(2024, 9, 9, 22, 15, 3), datetime.datetime(2024, 7, 14, 6, 12, 52), '001-474-009-8833x313', '+1-909-756-3792x311', 1892, Decimal('3.64')), (50, 35, datetime.datetime(2024, 2, 28, 13, 19, 38), datetime.datetime(2024, 3, 8, 18, 12), '+1-458-223-9008x11482', '+1-744-023-3149x969', 46, Decimal('36.50'))]\n"
     ]
    }
   ],
   "source": [
    "def run_query(query): \n",
    "    # Connect to the database\n",
    "    connection = mysql.connector.connect(\n",
    "        user=\"root\",\n",
    "        password=\"1234\",\n",
    "        host=\"127.0.0.1\",\n",
    "        port=\"3306\",  # Default MySQL port\n",
    "        database=\"telecom_db\"\n",
    "    )\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    try:\n",
    "        # Execute the query\n",
    "        cursor.execute(query)\n",
    "        # Fetch all rows from the query result\n",
    "        result = cursor.fetchall()\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        # Handle errors and return the error message\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        connection.close()\n",
    "\n",
    "query = \"SELECT * FROM call_data_records\"\n",
    "output = run_query(query)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(1, 'Natalie', 'Pierce', 'anthonyhartman@obrien.com', '+1-804-457-5152', datetime.date(2003, 10, 29), '8618 Amy Rapids Port Christian, NM 37068'), (2, 'Heather', 'Collins', 'jo31@hotmail.com', '001-452-918-0558x376', datetime.date(2015, 2, 5), '866 Cordova Canyon Simpsonberg, MA 77319'), (3, 'Jacqueline', 'Brown', 'christopher56@mccarty.com', '001-065-718-2695x66715', datetime.date(1947, 4, 7), '245 Kirk Mountain Suite 538 Kelleytown, NH 27835'), (4, 'Leslie', 'Rodriguez', 'williamsbrandon@russell.net', '(529)676-8492x11758', datetime.date(1921, 5, 2), '429 Robert Canyon Port Josephland, PA 14901'), (5, 'Bailey', 'Odom', 'latoya96@gmail.com', '001-635-938-2553x052', datetime.date(2004, 5, 3), '6075 Glenn Meadow South Sarah, MD 93195'), (6, 'Amanda', 'Decker', 'kmoyer@yahoo.com', '7906465435', datetime.date(2012, 1, 2), '4947 Ryan Village South Benjamin, SC 76206'), (7, 'Matthew', 'Scott', 'ramseyrobert@gmail.com', '367.201.7207', datetime.date(2002, 12, 26), '606 Howell Junctions Apt. 825 Autumnside, LA 57603'), (8, 'Matthew', 'Walker', 'qsmith@wright.com', '(094)123-4555x96249', datetime.date(1986, 3, 14), '1406 Larsen Drive Richardsside, ID 94509'), (9, 'David', 'Evans', 'bsantos@yahoo.com', '966-670-8447', datetime.date(1998, 9, 20), '7201 Moore Village South Justinmouth, AR 87430'), (10, 'Allen', 'Lane', 'johnsonmargaret@coleman.com', '001-729-039-6613x00322', datetime.date(1969, 2, 2), '865 Vicki Squares Suite 703 East Anthony, AL 26120'), (11, 'Lauren', 'Smith', 'trujillodavid@yahoo.com', '001-065-128-4586x36112', datetime.date(2019, 7, 9), 'Unit 8686 Box 4647 DPO AA 50369'), (12, 'Julia', 'Collins', 'lallen@lynch-johnston.com', '(112)768-9149x25533', datetime.date(1955, 11, 22), '756 Fleming Lake Apt. 368 West Tiffany, MI 98038'), (13, 'Gregory', 'Garner', 'elizabeth67@day-blevins.com', '(597)278-2413', datetime.date(1962, 8, 3), '4383 Ryan Mount Apt. 195 Lisabury, KY 64144'), (14, 'Luke', 'Jones', 'brianna63@yahoo.com', '(268)333-6988', datetime.date(1981, 11, 21), '82767 Schwartz Highway New Sarah, PA 48913'), (15, 'Stacy', 'Walker', 'richardsraymond@hotmail.com', '806.256.7605', datetime.date(2020, 8, 11), '32535 Randy Stream New Jacqueline, DE 51950'), (16, 'Lisa', 'Gardner', 'emmagutierrez@yahoo.com', '184-959-4283x42609', datetime.date(2020, 11, 29), '47399 Johnson Port Garciahaven, GA 11871'), (17, 'Christopher', 'Myers', 'ccummings@hotmail.com', '+1-202-332-7306x56451', datetime.date(2001, 10, 19), '81864 Miller Crescent Davidberg, IL 80672'), (18, 'Lisa', 'Dougherty', 'james94@hotmail.com', '096.179.9323x59114', datetime.date(2000, 2, 26), '3406 Jimenez Shoals South Christian, SC 75245'), (19, 'Jennifer', 'Cooley', 'josephwallace@hotmail.com', '001-012-449-2417x0559', datetime.date(1977, 8, 27), '8846 Susan Brook New Theresastad, IL 79660'), (20, 'Sophia', 'Hale', 'longzachary@cardenas.org', '8163995235', datetime.date(1996, 2, 1), '578 Christopher Ranch Suite 013 Jonathanbury, VA 47727'), (21, 'Edward', 'Garcia', 'dannycrawford@aguilar.com', '(492)439-2384x4089', datetime.date(1923, 8, 6), '620 Tyler Prairie Port Devinburgh, KS 42804'), (22, 'Christine', 'Rogers', 'cassieknapp@hotmail.com', '277.949.6635x2376', datetime.date(2000, 1, 31), '3157 Ashley Expressway South Leslie, SC 46505'), (23, 'Victoria', 'Lamb', 'ronald35@pope.com', '218-470-7160x9661', datetime.date(1966, 2, 28), '400 Welch Route Suite 504 Lake Kelly, KY 15890'), (24, 'James', 'Christensen', 'karencochran@yahoo.com', '(703)457-1650x9541', datetime.date(2017, 2, 11), '407 Mckee Trafficway East Leslieshire, AZ 85721'), (25, 'Frank', 'Flores', 'nwilson@smith.info', '147-728-5983x20051', datetime.date(2015, 2, 22), '3065 Harris Islands North Brianborough, PA 32374'), (26, 'Jennifer', 'Gutierrez', 'allenvictoria@flowers.biz', '+1-319-053-2492x10662', datetime.date(1916, 9, 17), '022 Allen Camp Lindamouth, LA 31565'), (27, 'Angela', 'Carter', 'bryandavila@gmail.com', '001-312-909-0021x36536', datetime.date(1970, 11, 7), '7271 Baker Trail Suite 519 Brooksstad, MA 33848'), (28, 'Janice', 'Welch', 'robertmcbride@pratt-williams.com', '(315)402-0971x528', datetime.date(2021, 1, 16), '81451 Brown Plains Suite 118 Tamarafurt, FL 98135'), (29, 'David', 'Yates', 'droth@downs-smith.com', '490-219-3440x495', datetime.date(1924, 10, 12), '866 Garcia Row New Sheilaport, DE 29513'), (30, 'Kelly', 'Gibson', 'brianmassey@hotmail.com', '618-857-8256', datetime.date(1930, 4, 13), 'USNS Anderson FPO AA 32345'), (31, 'Charles', 'Spencer', 'hayesbrittany@gmail.com', '+1-196-765-0838x603', datetime.date(2016, 6, 20), '0656 Ortiz Streets Apt. 873 Andersenmouth, NM 95354'), (32, 'Patrick', 'Davis', 'sandymorris@olson.biz', '3696171891', datetime.date(1926, 4, 14), '352 David Falls Apt. 976 East Patriciachester, LA 62085'), (33, 'Rebecca', 'Mason', 'williamsryan@watkins.com', '3916961898', datetime.date(1946, 12, 7), '50185 Allen Divide Apt. 111 Melissamouth, CT 93445'), (34, 'Lauren', 'George', 'nclark@elliott.com', '+1-541-903-9268x6003', datetime.date(1919, 2, 16), '29896 Christopher Mountains Apt. 547 South Nicholas, NH 57140'), (35, 'Thomas', 'Mueller', 'briankent@hotmail.com', '928-146-4942', datetime.date(1946, 10, 16), '7811 Harris Glens Apt. 394 West Arthur, SD 19620'), (36, 'Beth', 'Greer', 'mpadilla@gmail.com', '596-536-1090', datetime.date(1932, 3, 28), '38973 Lori Valley Apt. 492 West Laurahaven, DC 43905'), (37, 'Troy', 'Montoya', 'brian50@willis.com', '059-588-6413', datetime.date(2024, 3, 11), '7607 Amy Plaza Apt. 219 Justinton, NJ 37526'), (38, 'Linda', 'Phillips', 'underwooddenise@navarro.net', '496.193.7354x9616', datetime.date(1913, 6, 10), '819 Jacqueline Shoals South Ashleyside, AZ 52643'), (39, 'Kevin', 'Rodriguez', 'emilyhernandez@ortiz.com', '+1-507-033-9818', datetime.date(1959, 4, 24), '6317 White Mews Suite 888 Lake Deborah, MS 96636'), (40, 'Shaun', 'Chung', 'melissawhite@hotmail.com', '(443)277-6502x2202', datetime.date(1994, 1, 5), '8314 Roy Coves Apt. 254 Gomezshire, OK 50754'), (41, 'Michael', 'Mitchell', 'dustincarroll@lewis.com', '714.626.9275x4357', datetime.date(1916, 3, 16), '0039 Savannah Views Suite 852 South Sharon, UT 99232'), (42, 'Philip', 'Davis', 'richardsonkara@davis-morgan.biz', '498.673.8779x65201', datetime.date(1926, 10, 14), '379 White Plains Suite 214 South Hunterfurt, NY 32405'), (43, 'Dominique', 'King', 'julia42@rosales.com', '857-765-0819', datetime.date(1939, 7, 23), 'Unit 4196 Box 0142 DPO AP 40881'), (44, 'Lauren', 'Fernandez', 'gloria61@yahoo.com', '+1-657-129-3778', datetime.date(1956, 7, 2), '1370 Brett Valleys Michealbury, LA 68519'), (45, 'Tammy', 'Moore', 'bennettshelly@hotmail.com', '(589)648-4965', datetime.date(2022, 1, 3), '2099 Shaw Highway Apt. 283 Blankenshipfurt, AK 69347'), (46, 'Dylan', 'Salazar', 'pughwilliam@faulkner-boyd.net', '+1-952-153-1505x152', datetime.date(2019, 7, 3), '9938 Emma Mountains Suite 916 Robertport, UT 17450'), (47, 'Debra', 'Foster', 'youngjennifer@hotmail.com', '001-548-862-9267x182', datetime.date(1993, 9, 16), '040 Brianna Fords Apt. 423 Port Cindyport, KS 71584'), (48, 'Daniel', 'Arnold', 'nsmith@yahoo.com', '001-242-370-9853x7881', datetime.date(1985, 7, 31), '738 Hodges Highway Suite 223 Port William, IL 83166'), (49, 'John', 'Jones', 'christopher35@baker.com', '006-456-8533x7718', datetime.date(2002, 1, 15), '91252 Gonzalez Summit Williamsmouth, IA 09767'), (50, 'Kenneth', 'Manning', 'michaelcook@hotmail.com', '1696507542', datetime.date(2013, 9, 9), '6852 Eric Bypass Apt. 281 Port Jessica, SC 21948')]\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_query(query):\n",
    "    db_url = \"mysql+mysqlconnector://root:1234@localhost:3306/telecom_db\"\n",
    "    db = SQLDatabase.from_uri(db_url)\n",
    "    return db.run(query)\n",
    "\n",
    "run_query(\"SELECT * FROM customer_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining all the tools\n",
    "tools = [\n",
    "    # Tool(\n",
    "    #     name=\"rag_answer\",\n",
    "    #     func=create_rag_retrieval_chain,\n",
    "    #     description=\"\"\"Use this tool to answer questions about the loaded storybook.\n",
    "    #     Input should be a question about the story's content, characters, plot, or themes.\n",
    "    #     The tool uses RAG (Retrieval Augmented Generation) to provide accurate answers based on the story text.\n",
    "    #     Use this when questions are about the story's content or when you need to find specific information from the story.\"\"\"\n",
    "    # ),\n",
    "    Tool(\n",
    "        name=\"rag_answer\",\n",
    "        func=lambda query: create_rag_retrieval_chain().invoke(query),\n",
    "        description=\"\"\"Use this tool to answer questions about the loaded storybook.\n",
    "        Input should be a question about the story's content, characters, plot, or themes.\n",
    "        This tool uses Retrieval Augmented Generation (RAG) to provide accurate answers.\"\"\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"current_weather\",\n",
    "        func=get_current_weather,\n",
    "        description=\"Use this tool to get current weather information for any city. Input should be a city name.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"query_database\",\n",
    "        func=get_table_information,\n",
    "        description=\"\"\"Use this tool to query the employee management database and get information in natural language.\n",
    "        The tool can handle questions about:\n",
    "        - Employee details (name, salary, position, department, hire date)\n",
    "        - Department information (name, location, budget, manager)\n",
    "        - Statistical queries (averages, counts, grouping)\n",
    "        \n",
    "        Example questions:\n",
    "        - \"How many employees are in the Engineering department?\"\n",
    "        - \"What is the average salary by department?\"\n",
    "        - \"Who are the most recently hired employees?\"\n",
    "        - \"List all departments and their managers\"\n",
    "        - \"Show me employees with salaries above 70000\"\n",
    "        \n",
    "        Input should be a natural language question about employee or department data.\n",
    "        The tool will convert your question to SQL, execute it, and return a human-readable response.\"\"\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Creating React PromptTemplate\n",
    "template = '''Answer the following questions as best you can. You have access to the following tools:\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "(this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "BEGIN!\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}'''\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Initialization of memory to save all the past conversations\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"history\", k=3)\n",
    "\n",
    "# Create the agent and executor\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the run_agent function\n",
    "def run_agent(query):\n",
    "    try:\n",
    "        # Invoke the agent executor\n",
    "        agent_ans = agent_executor.invoke({\"input\": query})\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return \"Sorry, I could not process your query.\"\n",
    "\n",
    "    return agent_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find the total number of departments, I should query the employee management database.\n",
      "\n",
      "Action: query_database\n",
      "Action Input: How many departments are there?\u001b[0m\u001b[38;5;200m\u001b[1;3mcontent='There are 3 departments in the company: Engineering, Marketing, and Human Resources.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 502, 'total_tokens': 520, 'completion_time': 0.065454545, 'prompt_time': 0.07428232, 'queue_time': 0.019536975999999998, 'total_time': 0.139736865}, 'model_name': 'Llama-3.3-70b-Versatile', 'system_fingerprint': 'fp_fcc3b74982', 'finish_reason': 'stop', 'logprobs': None} id='run-8ef28fc1-927e-47c7-9fa0-df8c788c0cfc-0' usage_metadata={'input_tokens': 502, 'output_tokens': 18, 'total_tokens': 520}\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: There are 3 departments in the company.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ans = run_agent(\"total number of department\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To determine if I should carry an umbrella in Dallas, I need to check the current weather in Dallas. \n",
      "\n",
      "Action: current_weather\n",
      "Action Input: Dallas\u001b[0m\u001b[33;1m\u001b[1;3m{'city': 'Dallas', 'temperature': 13.86, 'feels_like': 13.02, 'humidity': 66, 'description': 'clear sky', 'wind_speed': 3.6}\u001b[0m\u001b[32;1m\u001b[1;3mSince the weather description in Dallas is 'clear sky', it's unlikely to rain. Therefore, I don't need to carry an umbrella.\n",
      "\n",
      "Thought: I now know the final answer\n",
      "Final Answer: No, you don't need to carry an umbrella. The current weather in Dallas is clear sky.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'i am currently in dallas should i carry an umbrella',\n",
       " 'history': '',\n",
       " 'output': \"No, you don't need to carry an umbrella. The current weather in Dallas is clear sky.\"}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_agent(\"i am currently in dallas should i carry an umbrella\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo determine the country of origin of the hero in the book, I should use the tool that provides information about the story's content, which is the rag_answer tool.\n",
      "\n",
      "Action: rag_answer\n",
      "Action Input: What country is the hero of the book from?\u001b[0m\u001b[36;1m\u001b[1;3m{'query': 'What country is the hero of the book from?', 'result': 'The hero of the book, Ulysses, is from the country of the Achaeans. He mentions that he and his people are on their way home from Troy and that they are the people of Agamemnon, son of Atreus. Specifically, Ulysses is from the region of Achaea, which is in ancient Greece.', 'source_documents': [Document(metadata={'source': 'c:\\\\Users\\\\ADMIN\\\\Tution\\\\Langchain_Leaern\\\\Project/dataset/odyssey.txt'}, page_content='Strangers, who are you? Where do sail from? Are you traders, or do\\nyou sail the sea as rovers, with your hands against every man, and\\nevery mans hand against you?\\n\\nWe were frightened out of our senses by his loud voice and monstrous\\nform, but I managed to say, We are Achaeans on our way home from Troy,\\nbut by the will of Jove, and stress of weather, we have been driven far\\nout of our course. We are the people of Agamemnon, son of Atreus, who\\nhas won infinite renown throughout the whole world, by sacking so great\\na city and killing so many people. We therefore humbly pray you to show\\nus some hospitality, and otherwise make us such presents as visitors\\nmay reasonably expect. May your excellency fear the wrath of heaven,\\nfor we are your suppliants, and Jove takes all respectable travellers\\nunder his protection, for he is the avenger of all suppliants and\\nforeigners in distress.'), Document(metadata={'source': 'c:\\\\Users\\\\ADMIN\\\\Tution\\\\Langchain_Leaern\\\\Project/dataset/odyssey.txt'}, page_content='And now, tell me and tell me true. Where have you been wandering, and\\nin what countries have you travelled? Tell us of the peoples\\nthemselves, and of their citieswho were hostile, savage and\\nuncivilised, and who, on the other hand, hospitable and humane. Tell us\\nalso why you are made so unhappy on hearing about the return of the\\nArgive Danaans from Troy. The gods arranged all this, and sent them\\ntheir misfortunes in order that future generations might have something\\nto sing about. Did you lose some brave kinsman of your wifes when you\\nwere before Troy? a son-in-law or father-in-lawwhich are the nearest\\nrelations a man has outside his own flesh and blood? or was it some\\nbrave and kindly-natured comradefor a good friend is as dear to a man\\nas his own brother?\\n\\n\\nBOOK IX\\n\\n\\nULYSSES DECLARES HIMSELF AND BEGINS HIS STORY-THE CICONS, LOTOPHAGI,\\nAND CYCLOPES.')]}\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: The hero of the book, Ulysses, is from the region of Achaea, which is in ancient Greece.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hero of the book is from which country',\n",
       " 'history': \"Human: name of all the department and their budeget\\nAI: The names and budgets of all departments are: \\n- Engineering with a budget of $1,500,000.00\\n- Marketing with a budget of $800,000.00\\n- Human Resources with a budget of $500,000.00\\nHuman: i am currently in dallas should i carry an umbrella\\nAI: Based on the current weather conditions in Dallas, which describe the weather as 'smoke' with a humidity of 71%, but do not mention rain, it is unlikely that you need to carry an umbrella for rain. However, the high humidity and smoke description might suggest fog or other conditions that could potentially require an umbrella. To be safe, you might consider carrying a light umbrella or checking more detailed forecasts for precipitation chances.\",\n",
       " 'output': 'The hero of the book, Ulysses, is from the region of Achaea, which is in ancient Greece.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_agent(\"hero of the book is from which country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: name of all the department and their budeget\n",
      "AI: The names and budgets of all departments are: \n",
      "- Engineering with a budget of $1,500,000.00\n",
      "- Marketing with a budget of $800,000.00\n",
      "- Human Resources with a budget of $500,000.00\n",
      "Human: i am currently in dallas should i carry an umbrella\n",
      "AI: Based on the current weather conditions in Dallas, which describe the weather as 'smoke' with a humidity of 71%, but do not mention rain, it is unlikely that you need to carry an umbrella for rain. However, the high humidity and smoke description might suggest fog or other conditions that could potentially require an umbrella. To be safe, you might consider carrying a light umbrella or checking more detailed forecasts for precipitation chances.\n",
      "Human: hero of the book is from which country\n",
      "AI: The hero of the book, Ulysses, is from the region of Achaea, which is in ancient Greece.\n"
     ]
    }
   ],
   "source": [
    "for message in memory.chat_memory.messages:\n",
    "    if message.type == \"human\":\n",
    "        print(f\"Human: {message.content}\")\n",
    "    elif message.type == \"ai\":\n",
    "        print(f\"AI: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
